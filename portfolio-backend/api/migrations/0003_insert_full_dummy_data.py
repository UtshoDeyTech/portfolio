# Generated by Django 5.2.7 on 2025-10-30 12:00

from django.db import migrations

def add_complete_data(apps, schema_editor):
    EducationEntry = apps.get_model('api', 'EducationEntry')
    ExperienceEntry = apps.get_model('api', 'ExperienceEntry')
    Project = apps.get_model('api', 'Project')
    ResearchPublication = apps.get_model('api', 'ResearchPublication')
    HomeData = apps.get_model('api', 'HomeData')
    BlogsData = apps.get_model('api', 'BlogsData')
    ResearchIcon = apps.get_model('api', 'ResearchIcon')

    # Delete existing data first
    EducationEntry.objects.all().delete()
    ExperienceEntry.objects.all().delete()
    Project.objects.all().delete()
    ResearchPublication.objects.all().delete()
    HomeData.objects.all().delete()
    BlogsData.objects.all().delete()
    ResearchIcon.objects.all().delete()

    # Add complete Education entries
    education_data = [
        {
            "institution": "BRAC University",
            "degree": "Master's degree",
            "field_of_study": "Computer Science",
            "education_type": "Graduate",
            "start_date": "Mar 2024",
            "end_date": "Aug 2025",
            "grade": "3.75",
            "grade_scale": "4.00",
            "location": "Dhaka, Bangladesh",
            "is_current": True,
            "institution_logo_url": "https://upload.wikimedia.org/wikipedia/en/thumb/4/40/BRAC_University_monogram.svg/1024px-BRAC_University_monogram.svg.png",
            "description": "Specializing in advanced topics such as Machine Learning, Cloud Computing, and Distributed Systems.",
            "achievements": [
                "Maintained CGPA 3.75",
                "Conducted research on decentralized recommendation systems"
            ],
            "is_visible": True,
            "display_order": 1
        },
        {
            "institution": "BRAC University",
            "degree": "Bachelor's degree",
            "field_of_study": "Computer Science",
            "education_type": "Undergraduate",
            "start_date": "Apr 2019",
            "end_date": "Dec 2022",
            "grade": "3.70",
            "grade_scale": "4.00",
            "location": "Dhaka, Bangladesh",
            "is_current": False,
            "institution_logo_url": "https://upload.wikimedia.org/wikipedia/en/thumb/4/40/BRAC_University_monogram.svg/1024px-BRAC_University_monogram.svg.png",
            "description": "Focused on software engineering, artificial intelligence, and backend development.",
            "achievements": [
                "Graduated with First Class Honors",
                "Developed a Decentralized Movie Recommendation System as final year project"
            ],
            "is_visible": True,
            "display_order": 2
        },
        {
            "institution": "Khulna Public College",
            "degree": "Higher Secondary Certificate",
            "field_of_study": "Science",
            "education_type": "Higher Secondary",
            "start_date": "May 2015",
            "end_date": "Apr 2017",
            "grade": "5.00",
            "grade_scale": "5.00",
            "location": "Khulna, Bangladesh",
            "is_current": False,
            "institution_logo_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Logo_of_Khulna_Public_College.jpg/330px-Logo_of_Khulna_Public_College.jpg",
            "description": "Completed HSC with distinction in Science group.",
            "achievements": [
                "Awarded Board Scholarship for academic excellence"
            ],
            "is_visible": True,
            "display_order": 3
        },
        {
            "institution": "Noapara Model Secondary School",
            "degree": "Secondary School Certificate",
            "field_of_study": "Science",
            "education_type": "Secondary",
            "start_date": "Jan 2003",
            "end_date": "Feb 2015",
            "grade": "5.00",
            "grade_scale": "5.00",
            "location": "Noapara, Bangladesh",
            "is_current": False,
            "institution_logo_url": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS5fWBAixXX-n2KyD3cOjbhKxM_yVP1pctxsA&s",
            "description": "Completed SSC with top grades in Science group.",
            "achievements": [
                "Secured GPA 5.00 with distinction in all subjects"
            ],
            "is_visible": True,
            "display_order": 4
        }
    ]

    for edu in education_data:
        EducationEntry.objects.create(**edu)

    # Add complete Experience entries
    experience_data = [
        {
            "company_name": "LEADS Corporation Limited",
            "role": "Senior Software Engineer",
            "employment_type": "Full-time",
            "location": "Dhaka, Bangladesh",
            "work_mode": "On-site",
            "start_date": "Oct 2025",
            "is_current": True,
            "description": "Working as a Senior Software Engineer focusing on scalable enterprise-grade banking applications using Java, Spring Boot, and Microservices architecture.",
            "achievements": [
                "Implemented secure microservice communication architecture using RabbitMQ and Redis.",
                "Optimized Oracle-based data pipelines for large-scale banking transactions.",
                "Applied SOLID design principles to modernize legacy systems."
            ],
            "skills": [
                "Spring Boot", "Java", "Banking", "Microservices", "Redis", "RabbitMQ",
                "SOLID Design Principles", "Git", "Oracle Database"
            ],
            "tech_stack": ["Java 17", "Spring Boot", "Redis", "RabbitMQ", "Oracle", "Git"],
            "is_visible": True,
            "display_order": 1
        },
        {
            "company_name": "InalyZe Bangladesh Ltd.",
            "role": "Python Developer (ML Specialist)",
            "employment_type": "Part-time",
            "location": "Remote",
            "work_mode": "Remote",
            "start_date": "Sep 2024",
            "is_current": True,
            "description": "Leading backend and AI infrastructure development for a multi-tenant document intelligence platform, integrating OpenAI, Pinecone, and AWS services.",
            "achievements": [
                "Built complete FastAPI backend with PostgreSQL and AWS S3 integration.",
                "Developed an AI-powered document chat system using React and OpenAI APIs.",
                "Containerized the entire solution using Docker and deployed on Kubernetes.",
                "Designed scalable multi-tenant architecture ensuring strict data isolation."
            ],
            "skills": [
                "FastAPI", "PostgreSQL", "Amazon S3", "Pinecone", "OpenAI", "React",
                "Docker", "Kubernetes", "Prompt Engineering", "Database Design"
            ],
            "tech_stack": [
                "Python", "FastAPI", "React", "PostgreSQL", "AWS", "Pinecone",
                "Docker", "Kubernetes"
            ],
            "is_visible": True,
            "display_order": 2
        },
        {
            "company_name": "Affpilot",
            "role": "Software Engineer",
            "employment_type": "Full-time",
            "location": "Mirpur DOHS, Dhaka",
            "work_mode": "On-site",
            "start_date": "Feb 2025",
            "end_date": "Sep 2025",
            "is_current": False,
            "description": "Worked on scalable backend systems integrating microservices with OAuth 2.0, Stripe, and RabbitMQ for high-traffic marketing automation products.",
            "achievements": [
                "Developed microservice-based backend with Python and Go.",
                "Integrated Stripe Connect for payment automation and subscription management.",
                "Built asynchronous processing pipelines using RabbitMQ and Celery.",
                "Deployed services with Docker and optimized database interactions with PostgreSQL."
            ],
            "skills": [
                "Python", "Go", "RabbitMQ", "Microservices", "gRPC", "REST APIs",
                "Docker", "OAuth2.0", "PostgreSQL", "Stripe Connect", "OpenAI API",
                "Gemini", "SERP API"
            ],
            "tech_stack": [
                "Python", "Go", "Docker", "RabbitMQ", "PostgreSQL", "Celery",
                "Stripe", "OpenAI"
            ],
            "is_visible": True,
            "display_order": 3
        },
        {
            "company_name": "AdsPillar",
            "role": "Machine Learning Engineer",
            "employment_type": "Full-time",
            "location": "Dhaka, Bangladesh",
            "work_mode": "On-site",
            "start_date": "Mar 2024",
            "end_date": "Jan 2025",
            "is_current": False,
            "description": "Developed AI-integrated social media automation platforms leveraging FastAPI, Supabase, and OpenAI APIs to power intelligent content scheduling and analytics.",
            "achievements": [
                "Integrated OpenAI, Gemini, and Hugging Face APIs for content generation.",
                "Built social media scheduling system with multi-platform integration.",
                "Developed backend using FastAPI and frontend using React.",
                "Designed database architecture using MySQL, PostgreSQL, and Supabase."
            ],
            "skills": [
                "FastAPI", "Supabase", "AWS", "PostgreSQL", "OpenAI API", "DALL¬∑E",
                "Prompt Engineering", "Chatbot Development", "Vector Databases",
                "Pinecone", "Python", "Database Design"
            ],
            "tech_stack": [
                "FastAPI", "React", "Supabase", "AWS", "OpenAI", "Hugging Face", "Pinecone"
            ],
            "is_visible": True,
            "display_order": 4
        },
        {
            "company_name": "InsureCow",
            "role": "Jr. Machine Learning Engineer",
            "employment_type": "Full-time",
            "location": "Dhaka, Bangladesh",
            "work_mode": "On-site",
            "start_date": "Jan 2024",
            "end_date": "Feb 2024",
            "is_current": False,
            "description": "Worked on data preprocessing and basic model prototyping for insurance-related AI systems.",
            "achievements": [
                "Collaborated with senior engineers to design ML pipelines.",
                "Developed scripts for dataset cleaning and transformation."
            ],
            "skills": ["Python", "Scikit-learn", "Data Preprocessing", "Machine Learning"],
            "tech_stack": ["Python", "Pandas", "Scikit-learn"],
            "is_visible": True,
            "display_order": 5
        },
        {
            "company_name": "Inflexionpoint Technologies (BD) Ltd.",
            "role": "Machine Learning Intern",
            "employment_type": "Internship",
            "location": "Dhaka, Bangladesh",
            "work_mode": "On-site",
            "start_date": "Aug 2023",
            "end_date": "Jan 2024",
            "is_current": False,
            "description": "Participated in AI internship program focusing on practical ML model building and deployment.",
            "achievements": [
                "Developed ML models for classification tasks using Python.",
                "Learned practical data engineering and model validation techniques."
            ],
            "skills": ["Python", "Machine Learning", "Data Analysis", "Model Evaluation"],
            "tech_stack": ["Python", "Pandas", "Scikit-learn", "TensorFlow"],
            "is_visible": True,
            "display_order": 6
        }
    ]

    for exp in experience_data:
        ExperienceEntry.objects.create(**exp)

    # Add complete Project entries
    projects_data = [
        {
            "slug": "askken-ai",
            "title": "AskKen.ai",
            "organization": "InalyZe Bangladesh Ltd.",
            "role": "Lead Backend Developer",
            "start_date": "Sep 2024",
            "type": "Professional",
            "short_description": "Advanced multi-tenant document intelligence platform for enterprise document management and AI chatbot automation.",
            "responsibilities": [
                "Led backend architecture design using FastAPI and PostgreSQL.",
                "Integrated document processing pipeline with Amazon S3 and Pinecone vector database.",
                "Developed AI chatbot with React and OpenAI integration for intelligent querying.",
                "Implemented secure multi-company authentication and role-based access control.",
                "Optimized for high user concurrency and large-scale document repositories.",
                "Containerized services with Docker and deployed on Kubernetes."
            ],
            "achievements": [
                "Reduced document query latency by 40% using vector optimization.",
                "Enabled support for 1M+ document embeddings.",
                "Enhanced multi-tenant scalability with database sharding."
            ],
            "skills": [
                "FastAPI", "Python", "PostgreSQL", "Amazon S3", "Pinecone", "Docker",
                "Kubernetes", "LLM Integration", "Prompt Engineering", "React"
            ],
            "tech_stack": {
                "backend": ["FastAPI", "Python", "PostgreSQL"],
                "frontend": ["React"],
                "ai_integration": ["OpenAI API", "Pinecone", "LangChain"],
                "devops": ["Docker", "Kubernetes", "Azure", "AWS"]
            },
            "project_url": "https://askken.ai",
            "contributor_count": 4,
            "collaboration": "Led a team of 3 engineers and 1 designer.",
            "tags": ["AI", "LLM", "Enterprise SaaS", "Multi-Tenant Architecture"],
            "is_visible": True,
            "display_order": 1
        },
        {
            "slug": "youtube-summarizer",
            "title": "YouTube Video Summarizer",
            "organization": "Affpilot",
            "role": "Python Developer",
            "start_date": "Mar 2025",
            "end_date": "Mar 2025",
            "type": "Personal Project",
            "short_description": "Desktop app to transcribe and summarize YouTube videos in multiple languages using Gemini API.",
            "responsibilities": [
                "Developed full-featured desktop app using PyQt.",
                "Integrated Gemini API for cross-language summarization.",
                "Implemented multi-threaded transcription for performance optimization.",
                "Designed markdown preview and summary history features."
            ],
            "achievements": [
                "Multi-language transcription (10+ languages)",
                "Cross-language summarization",
                "Intelligent summarization with Gemini API",
                "GUI with summary management"
            ],
            "skills": ["Gemini API", "PyQt", "Python", "Ffmpeg", "Prompt Engineering"],
            "tech_stack": {
                "language": "Python",
                "libraries": ["PyQt5", "Ffmpeg", "Gemini API", "LangChain"],
                "architecture": "Desktop Application"
            },
            "project_url": "https://github.com/UtshoDeyTech/youtube-video-summarizer",
            "contributor_count": 1,
            "tags": ["AI", "Multilingual", "Desktop App", "Gemini"],
            "is_visible": True,
            "display_order": 2
        },
        {
            "slug": "planpost-ai",
            "title": "PlanPostAi.com",
            "organization": "AdsPillar",
            "role": "Backend Engineer",
            "start_date": "Mar 2024",
            "end_date": "Jan 2025",
            "type": "Professional",
            "short_description": "AI-powered social media management platform that automates content creation and scheduling.",
            "responsibilities": [
                "Developed scalable backend with FastAPI and PostgreSQL.",
                "Integrated OpenAI, Llama, DALL-E, and Stability AI models for content generation.",
                "Created API endpoints for bulk content generation and intelligent scheduling.",
                "Implemented database optimization for high-throughput media uploads."
            ],
            "achievements": [
                "Reduced manual content creation time by 90%.",
                "Achieved efficient randomization algorithm for post scheduling.",
                "Handled 100K+ media generation requests with optimized concurrency."
            ],
            "skills": [
                "FastAPI", "PostgreSQL", "Docker", "Machine Learning", "Prompt Design",
                "Git", "Backend Architecture"
            ],
            "tech_stack": {
                "backend": ["FastAPI", "Python", "PostgreSQL"],
                "ai_integration": ["OpenAI", "Llama", "DALL-E", "Stability AI"],
                "devops": ["Docker", "AWS"],
                "version_control": ["Git", "GitHub"]
            },
            "project_url": "https://planpostai.com",
            "contributor_count": 5,
            "tags": ["AI", "Social Media", "Automation", "SaaS"],
            "is_visible": True,
            "display_order": 3
        },
        {
            "slug": "skin-cancer-detection",
            "title": "Skin Cancer Detection Using Custom CNN",
            "organization": "BRAC University",
            "role": "Research Student",
            "start_date": "Jan 2023",
            "end_date": "Jan 2025",
            "type": "Academic Project",
            "short_description": "CNN-based image classification model to detect multiple skin diseases using HAM10000 dataset.",
            "responsibilities": [
                "Designed and trained a custom CNN model for skin disease classification.",
                "Processed and augmented 28x28 RGB medical images.",
                "Evaluated model accuracy and optimized with hyperparameter tuning."
            ],
            "skills": ["TensorFlow", "Keras", "Python", "Deep Learning"],
            "tech_stack": {
                "frameworks": ["TensorFlow", "Keras"],
                "language": "Python",
                "dataset": ["HAM10000"]
            },
            "project_url": "https://github.com/UtshoDeyTech/skin-cancer-cnn",
            "tags": ["Deep Learning", "Healthcare", "CNN", "Computer Vision"],
            "is_visible": True,
            "display_order": 4
        },
        {
            "slug": "fashion-recommendation",
            "title": "Fashion Recommendation System",
            "organization": "BRAC University",
            "role": "Student Developer",
            "type": "Academic Project",
            "short_description": "A content-based image recommendation system built using Streamlit and feature extraction.",
            "responsibilities": [
                "Collected and preprocessed fashion image dataset from Kaggle.",
                "Extracted 2048-dimensional image features using deep models.",
                "Built similarity-based recommendation model.",
                "Deployed using Streamlit for user interaction."
            ],
            "skills": ["Streamlit", "Python", "Feature Extraction", "Content-Based Filtering"],
            "tech_stack": {
                "language": "Python",
                "frameworks": ["Streamlit"],
                "dataset": ["Kaggle Fashion Dataset"]
            },
            "tags": ["Recommendation System", "Computer Vision", "Web App"],
            "is_visible": True,
            "display_order": 5
        },
        {
            "slug": "movie-recommendation",
            "title": "Movie Recommendation System",
            "organization": "BRAC University",
            "role": "Student Developer",
            "type": "Academic Project",
            "short_description": "A content-based recommendation engine using IMDb data to suggest similar movies.",
            "responsibilities": [
                "Scraped and cleaned 25,000 movie entries from IMDb.",
                "Developed content-based similarity model using TF-IDF and cosine similarity.",
                "Built and deployed Streamlit web app for movie recommendations."
            ],
            "skills": ["Python", "Streamlit", "Scikit-learn", "Data Scraping"],
            "tech_stack": {
                "language": "Python",
                "frameworks": ["Streamlit", "Scikit-learn"],
                "dataset": ["IMDb Dataset"]
            },
            "tags": ["Recommendation System", "NLP", "Web App"],
            "is_visible": True,
            "display_order": 6
        }
    ]

    for proj in projects_data:
        Project.objects.create(**proj)

    # Add complete Research Publication entries
    research_data = [
        {
            "slug": "skin-cancer-cnn-research",
            "title": "Application of Deep Convolutional Neural Network in Multiclass Skin Cancer Classification Using Custom CNN Architecture",
            "authors": [
                "Nadia Shafique",
                "Kaynat Bint Shaheen",
                "Zarjis Husain Sikder",
                "Utsho Dey",
                "Sharforaz Rahman Swacha"
            ],
            "publication_date": "2023",
            "institution": "Brac University",
            "publication_type": "Undergraduate Thesis / Research Paper",
            "description": "This research proposes a custom CNN architecture for the classification of multiple skin diseases using 28x28 RGB images from the HAM10000 dataset. The model demonstrates superior performance in accuracy and efficiency compared to established pre-trained networks like ResNet50 and EfficientNetB0/B2.",
            "objectives": [
                "Develop a custom CNN model for multiclass skin disease classification.",
                "Compare performance with pre-trained models (ResNet50, EfficientNetB0/B2).",
                "Reduce training time and parameter complexity for efficient deployment."
            ],
            "dataset": "HAM10000",
            "metrics": ["Accuracy", "Precision", "Recall", "F1-Score"],
            "comparison_models": ["ResNet50", "EfficientNetB0", "EfficientNetB2"],
            "results_summary": "The proposed model achieved higher test accuracy with fewer trainable parameters and faster training per epoch than existing pre-trained models, making it suitable for resource-constrained environments.",
            "highlights": [
                "Improved test accuracy and reduced test loss.",
                "Lightweight model with lower computational requirements.",
                "Demonstrates potential for clinical diagnostic deployment."
            ],
            "tags": ["Deep Learning", "CNN", "Medical Imaging", "Healthcare AI", "Computer Vision"],
            "is_visible": True,
            "display_order": 1
        },
        {
            "slug": "house-price-prediction",
            "title": "Tailored House Price Prediction Insights for Dhaka and Chittagong City",
            "authors": [
                "Utsho Dey",
                "Md Sakhawat Hossain Rabbi",
                "Md Abrar Hamim",
                "Md Tarek Habib"
            ],
            "publication_date": "2024-09-11",
            "institution": "Brac University",
            "publication_type": "Conference Paper",
            "description": "This paper explores the use of advanced machine learning models to predict housing prices in Dhaka and Chittagong. Using a 3-year dataset, the study applies models such as XGBoost, Random Forest, and Linear Regression to evaluate performance based on R-squared and MSE metrics.",
            "objectives": [
                "Build accurate predictive models for house pricing in Bangladesh.",
                "Analyze the impact of data preprocessing and feature scaling on model accuracy.",
                "Compare traditional and ensemble ML methods for prediction."
            ],
            "dataset": "bdproperty.com (3-year dataset)",
            "metrics": ["R¬≤", "Mean Squared Error (MSE)"],
            "comparison_models": ["Linear Regression", "Random Forest", "XGBoost"],
            "results_summary": "Random Forest achieved the highest prediction accuracy, emphasizing the significance of preprocessing and feature selection for regression tasks.",
            "highlights": [
                "Comprehensive study on Dhaka and Chittagong housing markets.",
                "Feature scaling significantly improved performance metrics.",
                "Published in Springer Nature's conference proceedings."
            ],
            "tags": ["Machine Learning", "Regression", "Real Estate Analytics", "Data Science", "XGBoost"],
            "is_visible": True,
            "display_order": 2
        }
    ]

    for research in research_data:
        ResearchPublication.objects.create(**research)

    # Update HomeData
    HomeData.objects.create(
        data={
            "hero": {
                "name": "Utsho Dey",
                "tagline": "Senior Software Engineer | AI/ML Enthusiast | Full-Stack Developer",
                "bio": "Passionate about building scalable backend systems, integrating AI solutions, and solving complex engineering challenges. Experienced in Python, Java, Spring Boot, FastAPI, and cloud technologies.",
                "profile_image": "/images/profile.jpg",
                "resume_url": "/resume.pdf",
                "cta_buttons": {
                    "primary": {"text": "View My Work", "url": "/project"},
                    "secondary": {"text": "Contact Me", "url": "mailto:utshodey@example.com"}
                }
            },
            "about": {
                "title": "About Me",
                "paragraphs": [
                    "I'm a Senior Software Engineer with 2+ years of experience specializing in backend development, machine learning integration, and building enterprise-grade applications. Currently working at LEADS Corporation Limited, I focus on scalable banking solutions using Java and Spring Boot.",
                    "My expertise spans across Python (FastAPI, Django), Java (Spring Boot), cloud technologies (AWS, Docker, Kubernetes), and AI/ML integration (OpenAI, LangChain, Pinecone). I'm passionate about writing clean, maintainable code and implementing best practices in software architecture.",
                    "I hold a Master's degree in Computer Science from BRAC University, where I've conducted research on recommendation systems and deep learning. I enjoy contributing to open-source projects and sharing knowledge through technical blogs."
                ],
                "highlights": [
                    "Designed and deployed microservices architecture handling 100K+ requests",
                    "Reduced system latency by 40% through optimization techniques",
                    "Built AI-powered document intelligence platform serving enterprise clients",
                    "Published research in Springer Nature conference proceedings"
                ]
            },
            "stats": {
                "years_of_experience": "2+",
                "projects_completed": 10,
                "publications": 2,
                "technologies_used": 25
            },
            "skills": {
                "title": "Technical Skills",
                "categories": [
                    {
                        "name": "Backend Development",
                        "icon": "‚öôÔ∏è",
                        "skills": ["Python", "Java", "Spring Boot", "FastAPI", "Node.js", "Microservices", "REST APIs", "GraphQL"]
                    },
                    {
                        "name": "AI & Machine Learning",
                        "icon": "ü§ñ",
                        "skills": ["OpenAI", "LangChain", "TensorFlow", "Scikit-learn", "Pinecone", "Prompt Engineering", "LLM Integration"]
                    },
                    {
                        "name": "Databases",
                        "icon": "üóÑÔ∏è",
                        "skills": ["PostgreSQL", "MySQL", "MongoDB", "Redis", "Oracle", "Vector Databases"]
                    },
                    {
                        "name": "Cloud & DevOps",
                        "icon": "‚òÅÔ∏è",
                        "skills": ["Docker", "Kubernetes", "AWS", "Azure", "CI/CD", "Git", "Linux"]
                    },
                    {
                        "name": "Frontend",
                        "icon": "üé®",
                        "skills": ["React", "TypeScript", "Tailwind CSS", "HTML/CSS", "Responsive Design"]
                    },
                    {
                        "name": "Tools & Others",
                        "icon": "üõ†Ô∏è",
                        "skills": ["RabbitMQ", "Celery", "OAuth2.0", "Stripe", "Supabase", "PyQt"]
                    }
                ]
            },
            "social_links": {
                "github": "https://github.com/UtshoDeyTech",
                "linkedin": "https://www.linkedin.com/in/utshodey/",
                "email": "utshodey@example.com",
                "scholar": "https://scholar.google.com"
            },
            "cta": {
                "title": "Let's Work Together",
                "paragraph": "I'm always open to discussing new projects, creative ideas, or opportunities to be part of your vision.",
                "primary": {"text": "Get In Touch", "url": "mailto:utshodey@example.com"},
                "secondary": {"text": "View Portfolio", "url": "/project"}
            },
            "featured_sections": {
                "show_experience": True,
                "show_education": True,
                "show_projects": True,
                "show_research": True,
                "show_blog": True
            }
        }
    )

    # Update BlogsData
    BlogsData.objects.create(
        metadata={
            "site_title": "Tech Blog",
            "site_description": "Insights on Software Development, AI, and Technology",
            "posts_per_page": 6,
            "author_default": "Utsho Dey",
            "author_image_default": "/images/profile.jpg"
        },
        blogs=[],
        future_topics=[
            {
                "topic": "Machine Learning & AI",
                "description": "Deep dives into ML algorithms, LLM integration, prompt engineering, and practical AI applications in real-world projects.",
                "icon": "ü§ñ"
            },
            {
                "topic": "Backend Development",
                "description": "Best practices for building scalable backend systems with Python, FastAPI, Spring Boot, microservices architecture, and database optimization.",
                "icon": "‚öôÔ∏è"
            },
            {
                "topic": "Cloud & DevOps",
                "description": "Tutorials on Docker, Kubernetes, CI/CD pipelines, AWS services, and modern deployment strategies.",
                "icon": "‚òÅÔ∏è"
            },
            {
                "topic": "System Design",
                "description": "Exploring distributed systems, scalability patterns, database design, and architectural decisions for enterprise applications.",
                "icon": "üèóÔ∏è"
            },
            {
                "topic": "Full Stack Development",
                "description": "End-to-end development guides covering frontend frameworks (React), backend APIs, database management, and deployment.",
                "icon": "üíª"
            },
            {
                "topic": "Data Science & Analytics",
                "description": "Data preprocessing, visualization, statistical analysis, and building recommendation systems.",
                "icon": "üìä"
            },
            {
                "topic": "Software Engineering Best Practices",
                "description": "Code quality, testing strategies, design patterns, SOLID principles, and maintaining clean codebases.",
                "icon": "‚ú®"
            },
            {
                "topic": "Career & Learning",
                "description": "Tips for career growth in tech, learning resources, interview preparation, and navigating the software engineering landscape.",
                "icon": "üöÄ"
            }
        ]
    )

    # Add complete Research Icons
    research_icons_data = {
        "computer-science": {
            "path": "M9 17.25v1.007a3 3 0 0 1-.879 2.122L7.5 21h9l-.621-.621A3 3 0 0 1 15 18.257V17.25m6-12V15a2.25 2.25 0 0 1-2.25 2.25H5.25A2.25 2.25 0 0 1 3 15V5.25m18 0A2.25 2.25 0 0 0 18.75 3H5.25A2.25 2.25 0 0 0 3 5.25m18 0V12H3V5.25",
            "title": "Computer Science"
        },
        "physics": {
            "path": "M21 7.5l-9-5.25L3 7.5m18 0l-9 5.25m9-5.25v9l-9 5.25M3 7.5l9 5.25M3 7.5v9l9 5.25m0-9v9",
            "title": "Physics"
        },
        "biology": {
            "path": "M9.75 3.104v5.714a2.25 2.25 0 01-.659 1.591L5 14.5M9.75 3.104c-.251.023-.501.05-.75.082m.75-.082a24.301 24.301 0 014.5 0m0 0v5.714c0 .597.237 1.17.659 1.591L19.8 15.3M14.25 3.104c.251.023.501.05.75.082M19.8 15.3l-1.57.393A9.065 9.065 0 0112 15a9.065 9.065 0 00-6.23-.693L5 14.5",
            "title": "Biology"
        },
        "chemistry": {
            "path": "M9.75 3.104v5.714a2.25 2.25 0 01-.659 1.591L5 14.5M9.75 3.104c-.251.023-.501.05-.75.082m.75-.082a24.301 24.301 0 014.5 0m0 0v5.714c0 .597.237 1.17.659 1.591L19.8 15.3M14.25 3.104c.251.023.501.05.75.082M19.8 15.3l-1.57.393A9.065 9.065 0 0112 15",
            "title": "Chemistry"
        },
        "mathematics": {
            "path": "M15.75 15.75V18m-7.5-6.75h.008v.008H8.25v-.008zm0 2.25h.008v.008H8.25V13.5zm0 2.25h.008v.008H8.25v-.008zm0 2.25h.008v.008H8.25V18zm2.498-6.75h.007v.008h-.007v-.008zm0 2.25h.007v.008h-.007V13.5zm0 2.25h.007v.008h-.007v-.008zm0 2.25h.007v.008h-.007V18zm2.504-6.75h.008v.008h-.008v-.008zm0 2.25h.008v.008h-.008V13.5zm0 2.25h.008v.008h-.008v-.008zm0 2.25h.008v.008h-.008V18zm2.498-6.75h.008v.008h-.008v-.008zm0 2.25h.008v.008h-.008V13.5z",
            "title": "Mathematics"
        },
        "law": {
            "path": "M12 3c1.88 0 2.83.72 4.83 2.72 2 2 2.17 2.28 2.17 4.28 0 2-.17 2.28-2.17 4.28-2 2-2.95 2.72-4.83 2.72s-2.83-.72-4.83-2.72C5.17 12.28 5 12 5 10c0-2 .17-2.28 2.17-4.28C9.17 3.72 10.12 3 12 3zM6.5 10c0-1.5.5-2 2-3.5C10 5 10.5 4.5 12 4.5s2 .5 3.5 2c1.5 1.5 2 2 2 3.5s-.5 2-2 3.5c-1.5 1.5-2 2-3.5 2s-2-.5-3.5-2c-1.5-1.5-2-2-2-3.5z",
            "title": "Law"
        },
        "engineering": {
            "path": "M8.25 3v1.5M4.5 8.25H3m18 0h-1.5M4.5 12H3m18 0h-1.5m-15 3.75H3m18 0h-1.5M8.25 19.5V21M12 3v1.5m0 15V21m3.75-18v1.5m0 15V21m-9-1.5h10.5a2.25 2.25 0 002.25-2.25V6.75a2.25 2.25 0 00-2.25-2.25H6.75A2.25 2.25 0 004.5 6.75v10.5a2.25 2.25 0 002.25 2.25zm.75-12h9v9h-9v-9z",
            "title": "Engineering"
        }
    }

    for key, data in research_icons_data.items():
        ResearchIcon.objects.create(key=key, path=data["path"], title=data["title"])


def remove_complete_data(apps, schema_editor):
    EducationEntry = apps.get_model('api', 'EducationEntry')
    ExperienceEntry = apps.get_model('api', 'ExperienceEntry')
    Project = apps.get_model('api', 'Project')
    ResearchPublication = apps.get_model('api', 'ResearchPublication')
    HomeData = apps.get_model('api', 'HomeData')
    BlogsData = apps.get_model('api', 'BlogsData')
    ResearchIcon = apps.get_model('api', 'ResearchIcon')

    EducationEntry.objects.all().delete()
    ExperienceEntry.objects.all().delete()
    Project.objects.all().delete()
    ResearchPublication.objects.all().delete()
    HomeData.objects.all().delete()
    BlogsData.objects.all().delete()
    ResearchIcon.objects.all().delete()


class Migration(migrations.Migration):

    dependencies = [
        ('api', '0002_insert_dummy_data'),
    ]

    operations = [
        migrations.RunPython(add_complete_data, remove_complete_data),
    ]